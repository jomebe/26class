import React from 'react';
import { motion } from 'framer-motion';

interface VoiceAssistantProps {
  studentMood?: string;
}

const VoiceAssistant: React.FC<VoiceAssistantProps> = ({ studentMood = 'neutral' }) => {
  const [isListening, setIsListening] = React.useState(false);
  const [transcript, setTranscript] = React.useState('');
  const [response, setResponse] = React.useState('');
  const [loading, setLoading] = React.useState(false);
  const [conversationLog, setConversationLog] = React.useState<{type: 'user' | 'assistant', text: string}[]>([]);
  
  const recognitionRef = React.useRef<SpeechRecognition | null>(null);
  
  // Common class-related questions and answers
  const qaDatabase = {
    'ì‹œê°„í‘œ': 'ì˜¤ëŠ˜ ì‹œê°„í‘œëŠ” 1êµì‹œ êµ­ì–´, 2êµì‹œ ìˆ˜í•™, 3êµì‹œ ì˜ì–´, 4êµì‹œ ê³¼í•™, 5êµì‹œ ì‚¬íšŒ, 6êµì‹œ ì²´ìœ¡ì…ë‹ˆë‹¤.',
    'ê¸‰ì‹': 'ì˜¤ëŠ˜ ì ì‹¬ ë©”ë‰´ëŠ” ê¹€ì¹˜ì°Œê°œ, ì¡ê³¡ë°¥, ë©¸ì¹˜ë³¶ìŒ, ê¹ë‘ê¸°, ê³¼ì¼ì…ë‹ˆë‹¤.',
    'ì¼ì •': 'ì´ë²ˆ ì£¼ ì£¼ìš” ì¼ì •ì€ ìˆ˜ìš”ì¼ ì˜ì–´ í€´ì¦ˆ, ê¸ˆìš”ì¼ ì½”ë”© ì½˜í…ŒìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.',
    'ìˆ™ì œ': 'ì˜¤ëŠ˜ì˜ ìˆ™ì œëŠ” ìˆ˜í•™ êµê³¼ì„œ 42í˜ì´ì§€ 1-5ë²ˆ, ì˜ì–´ ë‹¨ì–´ 40ê°œ ì™¸ìš°ê¸°ì…ë‹ˆë‹¤.',
    'ë‹´ì„': '6ë°˜ ë‹´ì„ì„ ìƒë‹˜ì€ í™ê¸¸ë™ ì„ ìƒë‹˜ì´ì‹œë©°, ìƒë‹´ì€ ë§¤ì¼ ì ì‹¬ì‹œê°„ì— ê°€ëŠ¥í•©ë‹ˆë‹¤.',
    'ì‹œí—˜': 'ì¤‘ê°„ê³ ì‚¬ëŠ” 4ì›” 15ì¼ë¶€í„° 19ì¼ê¹Œì§€ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.',
    'í•™ê¸‰íšŒë¹„': 'í˜„ì¬ í•™ê¸‰íšŒë¹„ ì”ì•¡ì€ 235,000ì›ì…ë‹ˆë‹¤.',
    'ì²­ì†Œ': 'ì˜¤ëŠ˜ ì²­ì†Œ ë‹´ë‹¹ì€ 1ëª¨ë‘ ì…ë‹ˆë‹¤. ì°½í‹€ê³¼ ì±…ìƒ ì •ë¦¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤.',
    'ìë¦¬': 'ë‹¤ìŒ ì£¼ ì›”ìš”ì¼ë¶€í„° ìƒˆë¡œìš´ ìë¦¬ ë°°ì¹˜ê°€ ì‹œì‘ë©ë‹ˆë‹¤.',
    'ë™ì•„ë¦¬': 'ë™ì•„ë¦¬ ì‹ ì²­ì€ ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼ê¹Œì§€ì…ë‹ˆë‹¤. ì‹ ì²­ì„œëŠ” êµë¬´ì‹¤ì— ì œì¶œí•˜ì„¸ìš”.',
  };
  
  React.useEffect(() => {
    // Initialize speech recognition
    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      
      if (recognitionRef.current) {
        recognitionRef.current.continuous = false;
        recognitionRef.current.interimResults = false;
        recognitionRef.current.lang = 'ko-KR';
        
        recognitionRef.current.onresult = (event) => {
          const transcript = event.results[0][0].transcript;
          setTranscript(transcript);
          handleUserInput(transcript);
        };
        
        recognitionRef.current.onerror = (event) => {
          console.error('Speech recognition error:', event.error);
          setIsListening(false);
        };
        
        recognitionRef.current.onend = () => {
          setIsListening(false);
        };
      }
    }
    
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
    };
  }, []);
  
  const toggleListening = () => {
    if (isListening) {
      if (recognitionRef.current) {
        recognitionRef.current.abort();
      }
      setIsListening(false);
    } else {
      setTranscript('');
      if (recognitionRef.current) {
        recognitionRef.current.start();
      }
      setIsListening(true);
    }
  };
  
  const handleUserInput = (input: string) => {
    setLoading(true);
    
    // Add user message to conversation
    setConversationLog(prev => [...prev, { type: 'user', text: input }]);
    
    // Process the query and generate response
    setTimeout(() => {
      let foundResponse = 'ì£„ì†¡í•©ë‹ˆë‹¤, ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      
      // Check for keywords in the question
      Object.entries(qaDatabase).forEach(([keyword, answer]) => {
        if (input.includes(keyword)) {
          foundResponse = answer;
        }
      });
      
      // Check for additional context specific questions
      if (input.includes('ê¸°ë¶„') || input.includes('ë¶„ìœ„ê¸°')) {
        foundResponse = `í˜„ì¬ í•™ê¸‰ì˜ ë¶„ìœ„ê¸°ëŠ” ${studentMood === 'happy' ? 'ë°ê³  í™œê¸°ì°¬' : 
          studentMood === 'sad' ? 'ë‹¤ì†Œ ì¹¨ì²´ëœ' : 
          studentMood === 'angry' ? 'ì•½ê°„ ë¶ˆì•ˆì •í•œ' : 
          'í‰ì˜¨í•œ'} ìƒíƒœì…ë‹ˆë‹¤.`;
      } else if (input.includes('ì•ˆë…•') || input.includes('ë°˜ê°€ì›Œ')) {
        foundResponse = 'ì•ˆë…•í•˜ì„¸ìš”! 6ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?';
      } else if (input.includes('ê³ ë§ˆì›Œ') || input.includes('ê°ì‚¬')) {
        foundResponse = 'ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!';
      }
      
      setResponse(foundResponse);
      setConversationLog(prev => [...prev, { type: 'assistant', text: foundResponse }]);
      setLoading(false);
      
      // Text-to-speech for the response
      speak(foundResponse);
    }, 1000);
  };
  
  const speak = (text: string) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ko-KR';
      utterance.rate = 1.0;
      window.speechSynthesis.speak(utterance);
    }
  };
  
  const handleManualSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (transcript.trim()) {
      handleUserInput(transcript);
    }
  };

  return (
    <div className="p-6 bg-white dark:bg-gray-800 rounded-lg shadow-xl">
      <h2 className="text-2xl font-bold text-center mb-6">6ë°˜ AI ìŒì„± ì–´ì‹œìŠ¤í„´íŠ¸</h2>
      
      <div className="flex flex-col md:flex-row gap-6">
        <div className="w-full md:w-2/3">
          <div className="bg-gray-100 dark:bg-gray-700 rounded-lg p-4 h-[400px] overflow-y-auto">
            {conversationLog.length > 0 ? (
              <div className="space-y-4">
                {conversationLog.map((message, index) => (
                  <motion.div 
                    key={index}
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                    className={`p-3 rounded-lg max-w-[80%] ${
                      message.type === 'user' 
                        ? 'bg-sunrin-blue text-white ml-auto' 
                        : 'bg-gray-200 dark:bg-gray-600'
                    }`}
                  >
                    {message.text}
                  </motion.div>
                ))}
                {loading && (
                  <div className="flex items-center space-x-2 p-3 rounded-lg bg-gray-200 dark:bg-gray-600 max-w-[80%]">
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-pulse"></div>
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-pulse" style={{ animationDelay: '0.2s' }}></div>
                    <div className="w-2 h-2 bg-gray-500 rounded-full animate-pulse" style={{ animationDelay: '0.4s' }}></div>
                  </div>
                )}
              </div>
            ) : (
              <div className="h-full flex items-center justify-center text-gray-500">
                <p className="text-center">
                  ì•ˆë…•í•˜ì„¸ìš”! 6ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.<br />
                  ì‹œê°„í‘œ, ê¸‰ì‹, ì¼ì • ë“±ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.
                </p>
              </div>
            )}
          </div>
          
          <form onSubmit={handleManualSubmit} className="mt-4 flex gap-2">
            <input
              type="text"
              value={transcript}
              onChange={(e) => setTranscript(e.target.value)}
              className="flex-grow p-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-sunrin-blue"
              placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”..."
            />
            <button 
              type="button"
              onClick={toggleListening}
              className={`p-2 rounded-lg ${
                isListening 
                  ? 'bg-red-500 text-white' 
                  : 'bg-sunrin-blue text-white'
              }`}
            >
              {isListening ? (
                <span className="flex items-center">
                  <span className="w-3 h-3 bg-white rounded-full animate-pulse mr-2"></span>
                  ë“£ëŠ” ì¤‘...
                </span>
              ) : (
                'ğŸ¤'
              )}
            </button>
            <button 
              type="submit"
              className="bg-sunrin-blue text-white p-2 rounded-lg"
            >
              ì „ì†¡
            </button>
          </form>
        </div>
        
        <div className="w-full md:w-1/3">
          <div className="bg-gray-100 dark:bg-gray-700 rounded-lg p-4 h-full">
            <h3 className="font-bold mb-3 border-b pb-2">ìì£¼ ë¬»ëŠ” ì§ˆë¬¸</h3>
            
            <ul className="space-y-2">
              {Object.keys(qaDatabase).map((keyword, index) => (
                <li 
                  key={index} 
                  className="p-2 bg-gray-200 dark:bg-gray-600 rounded cursor-pointer hover:bg-gray-300 dark:hover:bg-gray-500 transition"
                  onClick={() => handleUserInput(`${keyword}ì´ ë­ì•¼?`)}
                >
                  {keyword} ì •ë³´
                </li>
              ))}
            </ul>
            
            <div className="mt-4 pt-2 border-t">
              <p className="text-sm text-gray-600 dark:text-gray-400">
                * ìŒì„± ì¸ì‹ì€ Chrome ë¸Œë¼ìš°ì €ì—ì„œ ê°€ì¥ ì˜ ì‘ë™í•©ë‹ˆë‹¤.
              </p>
              <p className="text-sm text-gray-600 dark:text-gray-400 mt-2">
                * ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default VoiceAssistant; 